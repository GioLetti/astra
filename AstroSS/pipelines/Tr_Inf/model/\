import numpy as np
import matplotlib.pyplot as plt
import os
from skimage import io
import sys
import h5py
import glob
import shutil
from joblib import Parallel, delayed
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, datasets, models
from torchsummary import summary
import torch.nn as nn
from collections import defaultdict
import torch.optim as optim
from torch.optim import lr_scheduler
import time
import copy
from aug_samples_single96 import *

test_folder_str = sys.argv[1]
if len(test_folder_str)==1:
    test_folder_str='00'+test_folder_str
else:
    test_folder_str='0'+test_folder_str
set_dir='/home/jbonato/Documents/U-Net/set/train_single'

items = os.listdir(set_dir)
print(len(items))
cnt=0
test=[]
for i in items:
    if 'SMALL_'+test_folder_str in i:
        print(i)
        test.append(i)
for i in test:
    items.remove(i)

print(len(items))
counter = 0
counter2 = 0
im = np.empty((96,96),dtype = np.float32 )
for item in items:
    path_to_item = os.path.join(set_dir,item)
    filename, file_extension = os.path.splitext(path_to_item)
    if os.path.isfile(path_to_item) and file_extension == '.tif' and filename[-2:]!='nf' and int(item[6:9])<26 :
        #print(filename)
        im = io.imread(path_to_item)
        if counter == 0: 
            out_im = im
            out_im = out_im[np.newaxis,:,:]
        else:
            out_im = np.concatenate((out_im,im[np.newaxis,:,:]),axis=0)
        dset= h5py.File(filename+'.hdf5','r') 
        proc_mask =  np.asarray(dset['Values'])
        soma_mask =  np.asarray(dset['Values_soma'])
        proc_mask[np.where(proc_mask==soma_mask)]=0
        back = np.ones((96,96),dtype=np.int64)-proc_mask-soma_mask
        back[back<0]=0
        mask = np.concatenate((proc_mask[:,:,np.newaxis],soma_mask[:,:,np.newaxis],back[:,:,np.newaxis]),axis=2).astype(np.float32)
        
        if counter ==0:
            label = mask
            label = label[np.newaxis,:,:,:]
        else:
            label = np.concatenate((label,mask[np.newaxis,:,:,:]),axis=0)
        counter+=1
    elif os.path.isfile(path_to_item) and file_extension == '.tif' and filename[-2:]!='nf' and int(item[6:9])>=26 :
        print(filename)
        im = io.imread(path_to_item)
        if counter2 == 0: 
            out_im2 = im
            out_im2 = out_im2[np.newaxis,:,:]
        else:
            out_im2 = np.concatenate((out_im2,im[np.newaxis,:,:]),axis=0)
        dset= h5py.File(filename+'.hdf5','r') 
        proc_mask =  np.asarray(dset['Values'])
        soma_mask =  np.asarray(dset['Values_soma'])
        proc_mask[np.where(proc_mask==soma_mask)]=0
        back = np.ones((96,96),dtype=np.int64)-proc_mask-soma_mask
        back[back<0]=0
        mask = np.concatenate((proc_mask[:,:,np.newaxis],soma_mask[:,:,np.newaxis],back[:,:,np.newaxis]),axis=2).astype(np.float32)
        
        if counter2 ==0:
            label2 = mask
            label2 = label2[np.newaxis,:,:,:]
        else:
            label2 = np.concatenate((label2,mask[np.newaxis,:,:,:]),axis=0)
        counter2+=1

label = np.swapaxes(label,1,3)
label = np.swapaxes(label,2,3)
out_im = out_im[:,np.newaxis,:,:].astype(np.float32)
label2 = np.swapaxes(label2,1,3)
label2 = np.swapaxes(label2,2,3)
out_im2 = out_im2[:,np.newaxis,:,:].astype(np.float32)

print('im shape:',out_im.shape)
print('label shape', label.shape)

counter = 0
im = np.empty((96,96),dtype = np.float32 )
for item in items:
    path_to_item = os.path.join(set_dir,item)
    filename, file_extension = os.path.splitext(path_to_item)
    if os.path.isfile(path_to_item) and file_extension == '.tif' and filename[-2:]=='nf':
        #print(filename)
        im = io.imread(path_to_item)
        if counter == 0: 
            out_im_nf = im
            out_im_nf = out_im_nf[np.newaxis,:,:]
        else:
            out_im_nf = np.concatenate((out_im_nf,im[np.newaxis,:,:]),axis=0)
        dset= h5py.File(filename+'.hdf5','r') 
        proc_mask =  np.asarray(dset['Values'])
        soma_mask =  np.asarray(dset['Values_soma'])
        proc_mask[np.where(proc_mask==soma_mask)]=0
        back = np.ones((96,96),dtype=np.int64)-proc_mask-soma_mask
        back[back<0]=0
        mask = np.concatenate((proc_mask[:,:,np.newaxis],soma_mask[:,:,np.newaxis],back[:,:,np.newaxis]),axis=2).astype(np.float32)
        
        if counter ==0:
            label_nf = mask
            label_nf = label_nf[np.newaxis,:,:,:]
        else:
            label_nf = np.concatenate((label_nf,mask[np.newaxis,:,:,:]),axis=0)
        counter+=1

label_nf = np.swapaxes(label_nf,1,3)
label_nf = np.swapaxes(label_nf,2,3)
out_im_nf = out_im_nf[:,np.newaxis,:,:].astype(np.float32)
print('im nf shape:',out_im_nf.shape)
print('label_nf shape', label_nf.shape)

N2 =  out_im2.shape[0]-(out_im2.shape[0]*2)//10

NN = out_im.shape[0]-(out_im.shape[0]*2)//10
print('NN',NN)
#val im
out_im_val = out_im[NN:,:,:,:] #out_im2[N2:,:,:,:]#
out_im_val = np.vstack((out_im_val,out_im_nf[NN:,:,:,:]))
#out_im_val = np.vstack((out_im_val,out_im2[N2:,:,:,:]))
#tr im
out_im =out_im[:NN,:,:,:]#out_im2[:N2,:,:,:]# 
out_im = np.vstack((out_im,out_im_nf[:NN,:,:,:]))
#out_im = np.vstack((out_im,out_im2[:N2,:,:,:]))

#val labels
label_val =label[NN:,:,:,:]# label2[N2:,:,:,:]#
label_val = np.vstack((label_val,label_nf[NN:,:,:,:]))
#label_val = np.vstack((label_val,label2[N2:,:,:,:]))
#tr labels
label =label[:NN,:,:,:]# label2[:N2,:,:,:]#
label = np.vstack((label,label_nf[:NN,:,:,:]))
#label = np.vstack((label,label2[:N2,:,:,:]))

def fun (i):
    N=96
    M=96
    
    im_cont = np.empty((18,1,N,M))
    mask_cont = np.empty((18,3,N,M))
    sample = np.empty((18,4,N,M))

    im_cont, mask_cont =  aug(im = out_im[i,0,:,:], mask =np.dstack((label[i,0,:,:],label[i,1,:,:])))
    
    sample[:,0,:,:]=im_cont[:,0,:,:]
    sample[:,1:,:,:]=mask_cont
    del im_cont,mask_cont
    return sample




list_samples = Parallel(n_jobs=12,verbose=1,require='sharedmem')(delayed(fun) (i) for i in range(out_im.shape[0]))
list_samples = np.asarray(list_samples)
print(list_samples.shape)
rank,batch,ch,N,M = list_samples.shape
list_samples = list_samples.reshape(rank*batch,ch,N,M)

out_im = np.vstack((out_im,list_samples[:,0,:,:][:,np.newaxis,:,:]))
label = np.vstack((label,list_samples[:,1:,:,:]))
label[label<0.2]=0.0
label[label>=0.2]=1.0
print('training set loaded')
print('im shape:',out_im_val.shape)
print('label_val shape', label_val.shape)

def fun_val (i):
    N=256
    M=256
    
    im_cont = np.empty((18,1,N,M))
    mask_cont = np.empty((18,3,N,M))
    sample = np.empty((18,4,N,M))

    im_cont, mask_cont =  a_s.aug(im = out_im[i,0,:,:], mask =np.dstack((label_val[i,0,:,:],label_val[i,1,:,:])))
    
    sample[:,0,:,:]=im_cont[:,0,:,:]
    sample[:,1:,:,:]=mask_cont
    del im_cont,mask_cont
    return sample



list_samples = Parallel(n_jobs=12,verbose=1,require='sharedmem')(delayed(fun) (i) for i in range(out_im_val.shape[0]))
list_samples = np.asarray(list_samples)
print(list_samples.shape)
rank,batch,ch,N,M = list_samples.shape
list_samples = list_samples.reshape(rank*batch,ch,N,M)

out_im_val = np.vstack((out_im_val,list_samples[:,0,:,:][:,np.newaxis,:,:]))
label_val = np.vstack((label_val,list_samples[:,1:,:,:]))
label_val[label_val<0.2]=0.0
label_val[label_val>=0.2]=1.0
#input('')
#n = input('Would you like to see a sample and its mask? type a number between 0 and '+str(out_im.shape[0])+', N otherwise\n')
#if n !='N':
#    n=int(n)
#    print(np.mean(out_im[n,0,:,:]),np.std(out_im[n,0,:,:]))
#
#    fig, ax = plt.subplots(figsize=(20, 20), ncols=4)
#    ax[0].imshow(out_im[n,0,:,:])
#    ax[1].imshow(label[n,0,:,:])
#    ax[2].imshow(label[n,1,:,:])
#    b=out_im[n,0,:,:]
#    A = np.zeros((80,80,3),dtype=np.float32)
#    maximum = 255/np.amax(b) #np.amax(conv_im)//250
#    c = b*maximum
#
#    A[:,:,0] = c
#    A[:,:,2] = 255*label[n,1,:,:]+255*label[n,0,:,:]
#    ax[3].imshow(A)
#    plt.show()
##///////////////////////////////////////// Visdom connection
from visdom import Visdom
import numpy as np
from six.moves import urllib
import time
vis = Visdom(port=8097, server="http://localhost")
Y = np.arange(1)
X = np.arange(1)
loss_vis = vis.line(
    X=np.column_stack((X,X)),
    Y=np.column_stack((Y,Y)),
    opts=dict(
        legend=['train','val'],
        xtickmin=0,
        xtickmax=50,
        xtickstep=10,
        ytickmin=0,
        ytickmax=10,
        ytickstep=1,
        title = 'Loss'
       
    ),
)

#///////////////////////////////////////// Here start the pytorch code

N_train=out_im.shape[0]-(out_im.shape[0]*2)//10

# GCN
mean_out_im = np.mean(np.mean(out_im,axis=3),axis=2)
print(mean_out_im.shape)
mean_out_im_val = np.mean(np.mean(out_im_val,axis=3),axis=2)
std_out_im = np.std(np.std(out_im,axis=3),axis=2)
std_out_im_val = np.std(np.std(out_im_val,axis=3),axis=2)

out_im = (out_im-mean_out_im[:,:,np.newaxis,np.newaxis])#/std_out_im[:,:,np.newaxis,np.newaxis]
out_im_val = (out_im_val - mean_out_im_val[:,:,np.newaxis,np.newaxis])#/std_out_im_val[:,:,np.newaxis,np.newaxis]
#print(np.mean(out_im))
#input('')

class SimDataset(Dataset):
    def __init__(self, count, transform=None,flag=True):
        if flag:
            self.input_images, self.target_masks = out_im[:,:,:,:],label[:,:,:,:]     
        else:
            self.input_images, self.target_masks = out_im_val[:,:,:,:],label_val[:,:,:,:]
        self.transform = transform
    
    def __len__(self):
        return len(self.input_images)
    
    def __getitem__(self, idx):        
        image = self.input_images[idx]
        mask = self.target_masks[idx]
        if self.transform:
            image = torch.from_numpy(image).float()
            mask = torch.from_numpy(mask).float()
        return [image, mask]

trans = True

train_set = SimDataset(count = N_train, transform = trans)
val_set = SimDataset(count = N_train , transform = trans, flag = False)

image_datasets = {
    'train': train_set, 'val': val_set
}

batch_size = 12

dataloaders = {
    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),
    'val': DataLoader(val_set, batch_size=12, shuffle=True, num_workers=0)
}


dataset_sizes = {
    x: len(image_datasets[x]) for x in image_datasets.keys()
}

print(dataset_sizes)
# model to import
#from model.Unet_Res152Back_nest import nestedUNetUp152
#from model.Unet_IncResV2_nest import IncResV2
from model.Unet_nest_5 import nestedUNetUp5
#from model.dense_up import dense_up
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

#model = IncResV2(3)
model = nestedUNetUp5(3)
#model= dense_up(3)
model = model.to(device)
# pre_trained=torch.load('/home/jbonato/Documents/U-Net/weights/pretr.pt')
# my_model = model.state_dict().items()
# for key,val in my_model:
#     if key[:9]=='conv_last':
#         print(key,'passed')
#     else:
       
#         model.state_dict()[key].copy_(pre_trained[key])

# ct=0
# for child in model.children():
#     if ct<=10:
#         print('freezing child ',ct)
#         for param in child.parameters():
#             param.requires_grad = False
#     ct +=1

summary(model, input_size=(1, 96,96),batch_size=12)

#Loss
def dice_loss(prediction, tar, smooth = 1.):
    
    pred = prediction.contiguous()
    target = tar.contiguous()    

    intersection = (pred * target).sum(dim=[1,2])
    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=[1,2]) + target.sum(dim=[1,2])+ smooth)))


    return loss.mean()

crit = nn.BCELoss()

loss_dict=[]
loss_dict_val=[]

def calc_loss(pred, target, metrics, bce_weight=0.5):
    bce = crit(pred, target)
    
    dice1 = dice_loss(pred[:,0,:,:], target[:,0,:,:])
    dice2 = dice_loss(pred[:,1,:,:], target[:,1,:,:])
    
    loss = bce * bce_weight + (dice2+ dice1)
    
    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)
    metrics['dice'] += (dice2+dice1).data.cpu().numpy() * target.size(0) 
    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)
    del  bce, dice1, dice2
    return loss

def print_metrics(metrics, epoch_samples, phase):    
    outputs = []
    for k in metrics.keys():
        outputs.append("{}: {:4f}".format(k, metrics[k] / epoch_samples))
        
    print("{}: {}".format(phase, ", ".join(outputs)))    

#train function
def train_model(model, optimizer, scheduler, num_epochs=25,best_loss=1e10):
    best_model_wts = copy.deepcopy(model.state_dict())
    
    
    

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)
        
        since = time.time()

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                scheduler.step()
                for param_group in optimizer.param_groups:
                    print("LR", param_group['lr'])
                    
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            metrics = defaultdict(float)
            epoch_samples = 0
           
            for inputs, labels in dataloaders[phase]:
                
                inputs = inputs.to(device)
                labels = labels.to(device)             
                #print('cached',torch.cuda.memory_cached(),'alloc',torch.cuda.memory_allocated())
                
                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    
                    outputs = model(inputs)
                    
                    loss = 0
                    for output in outputs:
                        loss += calc_loss(output, labels, metrics)
                    
                    loss /= len(output)
                    #for dense
                    #loss =calc_loss(outputs[3],labels,metrics)
                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
            
                # statistics
                epoch_samples += inputs.size(0)
            
            if phase == 'train':
                loss_dict.append(metrics['loss'] / epoch_samples)
                
            elif phase == 'val':
                loss_dict_val.append(metrics['loss'] / epoch_samples)

            print_metrics(metrics, epoch_samples, phase)
            epoch_loss = metrics['loss'] / epoch_samples

            # deep copy the model
            if phase == 'val' and epoch_loss < best_loss:
                print("saving best model")
                best_loss = epoch_loss
                best_model_wts = copy.deepcopy(model.state_dict())

        time_elapsed = time.time() - since
        vis.line(
                X=np.column_stack((np.arange(len(loss_dict)),np.arange(len(loss_dict)))),
                Y=np.column_stack((np.asarray(loss_dict),np.asarray(loss_dict_val))),
                win=loss_vis,
                opts=dict(
                    xtickmax=len(loss_dict),
                    legend=['train','val'],
                    title = 'Loss',
                    ytickmin=0,
                    xtickmin=0,
                    ytickmax=10,
                    ytickstep=1,
                    ),
                update='insert')
        torch.cuda.empty_cache()
        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best val loss: {:4f}'.format(best_loss))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model, best_loss

#////////////////////////////Training

weights_str='/home/jbonato/Documents/U-Net/weights/dense_up_'+test_folder_str+'.pt'
#weights_str='/home/jbonato/Documents/U-Net/weights/nest5_'+test_folder_str+'.pt'
weights_str_f='/home/jbonato/Documents/U-Net/weights/nest5_single_fine.pt'
optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)

exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=90, gamma=0.1)

model,loss_val = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=30)#120
torch.save(model.state_dict(),weights_str)
del model

# batch_size = 12

# dataloaders = {
#     'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),
#     'val': DataLoader(val_set, batch_size=12, shuffle=True, num_workers=0)
# }


# model = nestedUNetUp5(3)
# model = model.to(device)
# # summary(model_fine, input_size=(1, 80, 80),batch_size=1)
# model.load_state_dict(torch.load(weights_str))

# optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)

# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=100, gamma=0.1)
# model_fine,_ = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=100,best_loss=loss_val)
# torch.save(model_fine.state_dict(),weights_str_f)
