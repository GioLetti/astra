{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '/media/DATA/jbonato/astro_segm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "import h5py\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "from visdom import Visdom\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "############### Visualization\n",
    "\n",
    "from ipywidgets import Button, Layout\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display,clear_output,Video\n",
    "from copy import copy\n",
    "import numpy.ma as ma\n",
    "import matplotlib.colors as colors\n",
    "import imageio\n",
    "\n",
    "\n",
    "sys.path.insert(0,root_folder+'/RASTA/modules/')\n",
    "from gen_single_astro  import filt_im\n",
    "from sel_active_reg_gen import *\n",
    "from model.dense_up import dense_up\n",
    "\n",
    "from test_fun import gen_sc_mask,fix_mask,prob_calc,small_soma_to_proc,common_merge,art_rem_large,art_rem\n",
    "\n",
    "from get_traces import update_dict_DNN\n",
    "from gui_results import layout\n",
    "from mask_roi_from_fiji import create_mask\n",
    "\n",
    "# model to import\n",
    "model = dense_up(3)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device1 = torch.device('cpu')#('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "###\n",
    "MAX_ROI_AREA_PROC=30\n",
    "MU_PX = 1\n",
    "DOMAIN_RADIUS = 60\n",
    "# motion corr in extracting traces\n",
    "motion_corr=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "N=256\n",
    "M=256\n",
    "\n",
    "fov_list = [2]\n",
    "fov_DNN_weights_folder = root_folder+'/weights/dense_up' \n",
    "set_dir=root_folder+'/set1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [0, 40, 80, 120, 160],\n",
       " 'blocks': 15,\n",
       " 'threads': 32,\n",
       " 'BPM_ratio': 3,\n",
       " 'bb': 96,\n",
       " 'N_pix_st': 100,\n",
       " 'astr_min': 80,\n",
       " 'percentile': 80,\n",
       " 'pad': 5,\n",
       " 'astro_num': 4,\n",
       " 'init_th_': 0.6,\n",
       " 'decr_dim': 10,\n",
       " 'decr_th': 25,\n",
       " 'corr_int': False,\n",
       " 'gpu_flag': True,\n",
       " 'max_min': array([345,  89]),\n",
       " 'th1_p': 0.25,\n",
       " 'th2_p': 0.1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimDataset_test(Dataset):\n",
    "    def __init__(self,image_set):\n",
    "        self.input_images = image_set    \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "vis_flag = False\n",
    "##### LOAD PARAM DICT\n",
    "with open(set_dir+'.tmp/dict_dataset1.txt', \"rb\") as fp:   #Pickling\n",
    "    dict_param = pickle.load(fp)\n",
    "max_min = dict_param['max_min']\n",
    "dict_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import register_translation\n",
    "\n",
    "\n",
    "class Extr_miniROI():\n",
    "    \n",
    "    def __init__(self,Area_mu,mu_px,proc_to_split,soma,split_proc=False,dilate_ROI=1):\n",
    "        \n",
    "        \n",
    "        self.Area_mu = Area_mu\n",
    "        self.mu_px = mu_px\n",
    "        \n",
    "        self.Area_px = Area_mu/mu_px**2\n",
    "        self.proc_to_split = proc_to_split\n",
    "        self.soma = soma\n",
    "        self.split_proc = split_proc\n",
    "        self.dilate_ROI=dilate_ROI\n",
    "    \n",
    "    @staticmethod\n",
    "    def det_conn_comp(processes,soma,dilate_ROI):\n",
    "        #print(processes.shape)\n",
    "        N,M = processes.shape\n",
    "        num,comp = cv2.connectedComponents(processes.astype(np.uint8))\n",
    "        print('ROIS',num-1)\n",
    "        processes_out = np.zeros((num-1,N,M))\n",
    "        for k in range(1,num):\n",
    "            pt = np.where(comp==k)\n",
    "            buff = np.zeros((N,M))\n",
    "            buff[pt[0],pt[1]]=1\n",
    "            ###dilation\n",
    "            for _ in range(dilate_ROI):\n",
    "                element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
    "                buff = cv2.dilate(buff, element)\n",
    "            filtered = buff-soma-np.sum(processes_out,axis=0)\n",
    "            filtered[filtered<1]=0\n",
    "            processes_out[k-1,:,:]=filtered\n",
    "            \n",
    "        return processes_out\n",
    "\n",
    "    def get_k(self,area):\n",
    "        return area/self.Area_px\n",
    "    \n",
    "    def get_miniROI(self):\n",
    "        \n",
    "        self.proc_to_split = self.det_conn_comp(self.proc_to_split,self.soma,self.dilate_ROI)\n",
    "        #print('check size',self.proc_to_split.shape)\n",
    "        if self.split_proc :\n",
    "            Nroi,H,W = self.proc_to_split.shape\n",
    "            collROI = []\n",
    "            for i in range(Nroi):\n",
    "                N = np.sum(self.proc_to_split[i,:,:])\n",
    "                k = self.get_k(N)\n",
    "                #print('ratio',k,int(k))\n",
    "                if int(k)<=1:\n",
    "                    collROI.append(self.proc_to_split[i,:,:][:,:,np.newaxis])\n",
    "                else:\n",
    "                    rr = k.astype(np.int64)\n",
    "                    buff = np.zeros((H,W,rr))\n",
    "                    pt = np.where(self.proc_to_split[i,:,:]==1)\n",
    "                    X = np.asarray([pt[0],pt[1]]).T\n",
    "\n",
    "                    kmeans = KMeans(n_clusters=int(k), random_state=0).fit(X)\n",
    "                    labels = kmeans.labels_\n",
    "\n",
    "                    for j in range(int(k)):\n",
    "                        pt_lb = np.where(labels==j)\n",
    "                        buff[X[pt_lb[0],0],X[pt_lb[0],1],j]=1\n",
    "\n",
    "                    collROI.append(buff)\n",
    "            out = collROI[0]       \n",
    "\n",
    "            if len(collROI)>1:\n",
    "                for i in range(1,len(collROI)):  \n",
    "                    #print(collROI[i].shape)\n",
    "                    out = np.dstack((out,collROI[i]))\n",
    "            print('SPLIT DONE',out.shape)\n",
    "            return out\n",
    "        else:\n",
    "            print('SPLIT DONE',self.proc_to_split.shape)\n",
    "            out = np.moveaxis(self.proc_to_split,[0,1,2],[2,0,1])\n",
    "            return out\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_signals(roi,stack):\n",
    "    T,_,_ = stack.shape\n",
    "    _,_,N = roi.shape\n",
    "    \n",
    "    signals = []\n",
    "    for i in range(N-1):\n",
    "        pt = np.where(roi[:,:,i]==1)\n",
    "        #ev add single pixels rem\n",
    "        signals.append(np.mean(stack[:,pt[0],pt[1]],axis=1))\n",
    "    return signals\n",
    "\n",
    "def get_signal(roi,stack):\n",
    "    pt = np.where(roi==1)\n",
    "    return np.mean(stack[:,pt[0],pt[1]],axis=1)\n",
    "\n",
    "def allineate_stack(stack,shift,r_domain):\n",
    "    T,N,M = stack.shape\n",
    "    stack_out = np.zeros_like(stack)\n",
    "    stack_pad = np.pad(stack,((0,0),(r_domain,r_domain),(r_domain,r_domain)), 'constant', constant_values=0)\n",
    "    for t in range(T):\n",
    "        stack_out[t,:,:]= stack_pad[t,r_domain-shift[t,0]:r_domain+N-shift[t,0],r_domain-shift[t,1]:r_domain+M-shift[t,1]]\n",
    "    return stack_out\n",
    "\n",
    "def box(cX,cY,radius,N):\n",
    "    casex=2\n",
    "    casey=2\n",
    "    if cX-radius<0:\n",
    "        casex=0\n",
    "    elif cX+radius>N:\n",
    "        casex=1\n",
    "    if cY-radius<0:\n",
    "        casey=0\n",
    "    elif cY+radius>N:\n",
    "        casey=1\n",
    "    #x\n",
    "    if casex==2:\n",
    "        c1x=cX-radius\n",
    "        c2x=cX+radius\n",
    "    elif casex==0:\n",
    "        c1x=0\n",
    "        c2x=2*radius\n",
    "    else:\n",
    "        c1x=N-2*radius\n",
    "        c2x=N\n",
    "    #y\n",
    "    if casey==2:\n",
    "        c1y=cY-radius\n",
    "        c2y=cY+radius\n",
    "    elif casey==0:\n",
    "        c1y=0\n",
    "        c2y=2*radius\n",
    "    else:\n",
    "        c1y=N-2*radius\n",
    "        c2y=N\n",
    "    return c1x,c1y,c2x,c2y\n",
    "\n",
    "def create_bb_coord_domain(soma_mask,radius = 60):\n",
    "   \n",
    "    N,M = soma_mask.shape\n",
    "    soma = np.empty_like(soma_mask)\n",
    "    soma = soma_mask.copy()\n",
    "    soma[soma>0.1]=255\n",
    "\n",
    "    _,thresh = cv2.threshold(np.uint8(soma),127,255,0)\n",
    "\n",
    "    # find contours in the binary image\n",
    "    contours, _= cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # loop over the contours\n",
    "    #list of array with the coordinate\n",
    "    coord_list_st = []\n",
    "    coord_list_cell = []\n",
    "    coord_list_circle = []\n",
    "    for c in contours:\n",
    "        if c.shape[0]!=1:\n",
    "            im_buff = np.zeros((N,M))\n",
    "            # compute the center of the contour\n",
    "            M = cv2.moments(c)\n",
    "            cX = int(M[\"m10\"] / (M[\"m00\"]+1e-5))\n",
    "            cY = int(M[\"m01\"] / (M[\"m00\"]+1e-5))\n",
    "            #compute the region of astrocyte radius 60\n",
    "            c1x,c1y,c2x,c2y = box(cX,cY,48,N)\n",
    "            coord_list_cell.append([c1x,c1y,c2x,c2y])\n",
    "            c1x,c1y,c2x,c2y = box(cX,cY,radius,N)\n",
    "            cv2.circle(im_buff,(cX,cY),radius,(255,0,0),thickness =-1,lineType=8)\n",
    "            coord_circle = np.where(im_buff==255)\n",
    "            coord_list_circle.append(coord_circle)\n",
    "\n",
    "            coord = np.array([c1x,c1y,c2x,c2y])\n",
    "            coord_list_st.append(coord)\n",
    "        return coord_list_st,coord_list_circle, coord_list_cell\n",
    "\n",
    "    \n",
    "class Motion_Correction():\n",
    "    \"\"\" inputs: \n",
    "        - im_stream numpy array of shape TxNxM (N and M can be equal) \n",
    "        - ref_image an image numpy array of shape NxM(same dim of im_stream)\n",
    "        - eventually ref_frame a scalar\n",
    "        outputs:\n",
    "        - shift \n",
    "        This class return a stream of image of shape TxNxN (numpy array), all the images are corrected with the algorithm \n",
    "        Guizar-Sicairos et al., “Efficient subpixel image registration algorithms,”Optics Letters 33, 156-158 (2008).\n",
    "        \n",
    "        Obs.\n",
    "        -This class must be initialized with the pixel precision that are required\n",
    "        -If ref_image and ref_frame are not given the reference is the first frame\n",
    "    \"\"\"\n",
    "    def __init__(self,pix_precision):\n",
    "        self.pix_precision = pix_precision\n",
    "        \n",
    "\n",
    "    def motion_corr(self,im_stream,ref_image=None,ref_frame=None):\n",
    "        if (ref_frame != None and ref_image.all() != None):\n",
    "            raise Exception('ref_frame or ref_image must be None')\n",
    "                    \n",
    "        T,cols,rows = im_stream.shape\n",
    "\n",
    "        if(ref_image.all()!=None):\n",
    "            pass\n",
    "        elif(ref_frame!=None):\n",
    "            ref_image = im_stream[ref_frame,:,:]\n",
    "        else:\n",
    "            ref_image = im_stream[0,:,:]\n",
    "\n",
    "        shift_vec = np.empty((T,2),dtype=np.float64)\n",
    "        for i in range(T):\n",
    "            shift_vec[i,:],_,_ = register_translation(ref_image, im_stream[i,:,:],upsample_factor=self.pix_precision)\n",
    "\n",
    "        X_shift = np.array([np.arange(T),shift_vec[:,1]])\n",
    "        Y_shift = np.array([np.arange(T),shift_vec[:,0]])\n",
    "        \n",
    "        self.X_shift = X_shift\n",
    "        self.Y_shift = Y_shift\n",
    "        return shift_vec.astype(np.int64)\n",
    "    \n",
    "    def apply_corr(self,im_stream2):\n",
    "        \n",
    "        T,cols,rows = im_stream2.shape\n",
    "        for i in range(T):\n",
    "            \n",
    "            M = np.float32([[1,0,self.X_shift[i,1]],[0,1,self.Y_shift[i,0]]])\n",
    "            im_stream2[i,:,:] = cv2.warpAffine(im_stream2[i,:,:],M,(rows,cols))\n",
    "        return im_stream2\n",
    "        \n",
    "def update_dict_DNN(dict_im,single_astro_roi,fov_num,motion_corr,MAX_ROI_AREA_PROC,MU_PX,MiniROI=False):\n",
    "    dict_im['Single_cell_mask_'+fov_num] = single_astro_roi\n",
    "    dict_roi={}\n",
    "    dict_traces={}\n",
    "    dict_cell_coord={}\n",
    "    dict_cell_shift={}\n",
    "    dict_im['Cell_num_'+fov_num] = single_astro_roi.shape[0]\n",
    "    \n",
    "    print(\"ROI NUM\",single_astro_roi.shape[0])\n",
    "   \n",
    "    if motion_corr : mc  = Motion_Correction(pix_precision=1)\n",
    "    \n",
    "    for s_roi_num in range(single_astro_roi.shape[0]):\n",
    "        name = str(s_roi_num)\n",
    "        \n",
    "        coord_list_st,coord_list_circle, coord_list_cell = create_bb_coord_domain(single_astro_roi[s_roi_num,:,:,1])\n",
    "        dict_cell_coord['ST_'+f'{name:0>3}'] = coord_list_st[0]\n",
    "        dict_cell_coord['CIRCLE_'+f'{name:0>3}'] = coord_list_circle[0]\n",
    "        dict_cell_coord['BB_cell_'+f'{name:0>3}'] = coord_list_cell[0]\n",
    "        if motion_corr:\n",
    "            coord_bb = coord_list_cell[0]\n",
    "#             print('Shift_'+f'{name:0>3}')\n",
    "            dict_cell_shift['Shift_'+f'{name:0>3}'] = mc.motion_corr(dict_im['t-series_'+fov_num][:,coord_bb[1]:coord_bb[3],coord_bb[0]:coord_bb[2]],\\\n",
    "                           ref_image=np.mean(dict_im['t-series_'+fov_num][:,coord_bb[1]:coord_bb[3],coord_bb[0]:coord_bb[2]],axis=0))\n",
    "        \n",
    "            stack_buffer = allineate_stack(dict_im['t-series_'+fov_num],dict_cell_shift['Shift_'+f'{name:0>3}'],r_domain=dict_im['Astro_domain_radius'])\n",
    "        else:\n",
    "            stack_buffer = dict_im['t-series_'+fov_num]\n",
    "            \n",
    "        print(50*'%','Extracting cell:',s_roi_num)\n",
    "        constr_split_roi = Extr_miniROI(MAX_ROI_AREA_PROC,MU_PX,single_astro_roi[s_roi_num,:,:,0],single_astro_roi[s_roi_num,:,:,1],MiniROI)\n",
    "        arr_out_proc = constr_split_roi.get_miniROI()\n",
    "        if  s_roi_num==0:\n",
    "            list_out=arr_out_proc\n",
    "        else:\n",
    "            print(list_out.shape,arr_out_proc.shape)\n",
    "            list_out = np.dstack((list_out,arr_out_proc))\n",
    "       \n",
    "        dict_roi['Soma_'+f'{name:0>3}'] = np.where(single_astro_roi[s_roi_num,:,:,1]==1)\n",
    "        dict_traces['Soma_'+f'{name:0>3}'] = get_signal(single_astro_roi[s_roi_num,:,:,1],stack_buffer)\n",
    "        for proc_num in range(arr_out_proc.shape[2]):\n",
    "            name_proc = str(proc_num)\n",
    "            dict_roi['Proc_'+f'{name:0>3}'+'_'+f'{name_proc:0>3}'] = np.where(arr_out_proc[:,:,proc_num]==1)\n",
    "            dict_traces['Proc_'+f'{name:0>3}'+'_'+f'{name_proc:0>3}']  = get_signal(arr_out_proc[:,:,proc_num],stack_buffer)\n",
    "        print('Extraction: done')\n",
    "    \n",
    "    dict_im['Signals_extr_'+fov_num] = dict_traces\n",
    "    dict_im['ROI_'+fov_num] = dict_roi\n",
    "    dict_im['crop_coord_ROI_'+fov_num] = dict_cell_coord\n",
    "    \n",
    "    if motion_corr:\n",
    "        dict_im['shift_ROI_'+fov_num] = None\n",
    "    else:\n",
    "        dict_im['shift_ROI_'+fov_num] = dict_cell_coord\n",
    "        \n",
    "    #### for Visualization purposes\n",
    "    list_out = np.dstack((list_out,dict_im['Final_Mask_'+fov_num][:,:,1:]))\n",
    "    dict_im['Final_Mask_fraction_'+fov_num] = list_out\n",
    "    \n",
    "    return dict_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/DATA/jbonato/astro_segm/set1/2/TSeries-04082019-1513-1251_Ch2__movie_corrected_aligned.tiff\n",
      "Init threshold 330.0\n",
      "Zones 12\n",
      "file loading...\n",
      "check (550, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "dict_im = {}\n",
    "dict_im['Astro_domain_radius'] = DOMAIN_RADIUS\n",
    "for jj in fov_list:\n",
    "    #im_list = []\n",
    "    Res_1 = np.zeros((N,M,3))\n",
    "\n",
    "    test_folder_str =str(jj)\n",
    "    if len(test_folder_str)==1:\n",
    "        test_folder_str1='00'+test_folder_str\n",
    "    else:\n",
    "        test_folder_str1='0'+test_folder_str\n",
    "\n",
    "    model.load_state_dict(torch.load(fov_DNN_weights_folder+test_folder_str1+'D1.pt'))\n",
    "    \n",
    "    #collect stack to analyze\n",
    "    \n",
    "    stack_dir = '/media/DATA/jbonato/astro_segm/set1/'+test_folder_str+'/'\n",
    "\n",
    "    items_stack = os.listdir(stack_dir)\n",
    "\n",
    "    print(stack_dir + items_stack[0])\n",
    "    stack = io.imread(stack_dir + items_stack[0]).astype(np.uint16)\n",
    "    dict_im['t-series_'+test_folder_str1] = stack\n",
    "    frames,_,_ = stack.shape\n",
    "\n",
    "    a_reg = sel_active_reg(stack.astype(np.float32),dict_param)\n",
    "    mask = a_reg.get_mask()\n",
    "    mask = fix_mask(mask)\n",
    "    \n",
    "    #im_list.append([mask,'Active Regions'])\n",
    "    dict_im['Active Regions_'+test_folder_str1] = mask\n",
    "    filter_ = filt_im(stack_dir + items_stack[0],mask,dict_param['bb']-2*dict_param['pad'])\n",
    "    _, image_to_plot = filter_.create_img()\n",
    "    # for other dataset spatia_pp methods can be called from filter_, outputs are stack filtered and spatial map enhanced  \n",
    "    #im_list.append([image_to_plot,'Enhanced'])\n",
    "    dict_im['Enhanced_'+test_folder_str1] = image_to_plot\n",
    "    coord_l = filter_.get_instances()\n",
    "    \n",
    "    assert coord_l!=0, 'Check Active region extraction module'\n",
    "    \n",
    "    \n",
    "    image_stack = np.empty((len(coord_l),dict_param['bb'],dict_param['bb'])) \n",
    "\n",
    "    image_stack,filt_imageL = filter_.save_im()#select the padding val 5 is default\n",
    "    \n",
    "    \n",
    "    image_set = image_stack[:,0,:,:]\n",
    "    image_set = image_set[:,np.newaxis,:,:]\n",
    "\n",
    "    imageL_set = image_to_plot*filt_imageL\n",
    "    imageL_set-=np.mean(imageL_set)\n",
    "    imageL_set= imageL_set[np.newaxis,np.newaxis,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    ######################################## Prob Map\n",
    "    test_datasetL = SimDataset_test(imageL_set)\n",
    "    test_loader = DataLoader(test_datasetL, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    inputs = next(iter(test_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model(inputs)\n",
    "    \n",
    "    pred_mean = pred.data.cpu().numpy()\n",
    "    del test_datasetL,test_loader, inputs,pred\n",
    "    \n",
    "    mean = pred_mean[0]\n",
    "    maxim = np.amax(mean,axis=0)\n",
    "    mean[mean<maxim]=0\n",
    "        \n",
    "    prob_mapPL,sm_ent = prob_calc(mean[1,:,:],max_min[0],max_min[1])\n",
    "    \n",
    "    #im_list.append([prob_mapPL,'Prob. Map'])\n",
    "    dict_im['Prob. Map PL_'+test_folder_str1] = prob_mapPL\n",
    "    #im_list.append([sm_ent,'Prob. Map'])\n",
    "    dict_im['Prob. Map_'+test_folder_str1] = sm_ent\n",
    "    ########################################## putative single cell\n",
    "    test_dataset_S = SimDataset_test(image_set)\n",
    "    test_loader = DataLoader(test_dataset_S, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    \n",
    "    pred_mean=[]\n",
    "    for inputs in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        pred = model(inputs)\n",
    "        pred_mean.append(pred.data.cpu().numpy())\n",
    "        del inputs,pred\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for j in range(1,len(pred_mean)):\n",
    "        pred_mean[0]=np.vstack((pred_mean[0],pred_mean[j]))\n",
    "\n",
    "    prob_map = np.zeros((N,M,2))\n",
    "\n",
    "    for i in range(len(coord_l)):\n",
    "        mean= np.zeros((3,dict_param['bb'],dict_param['bb']))\n",
    "        mean = pred_mean[0][i,:,:,:].copy()\n",
    "        \n",
    "        maxim = np.amax(mean,axis=0)\n",
    "        mean[mean<maxim]=0\n",
    "        mean[mean>=maxim]=1\n",
    "\n",
    "        small_soma = small_soma_to_proc(mean[1,:,:],N = int((2/3)*max_min[1])) ####remove too small somata segmentated\n",
    "        mean[0,:,:]+=small_soma\n",
    "        mean[1,:,:]-=small_soma\n",
    "        \n",
    "        coord = coord_l[i]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],0] += mean[0,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],1] += mean[1,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "\n",
    "\n",
    "\n",
    "    Res_1[:,:,0] -= Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    ######### can be wrapped\n",
    "    \n",
    "    soma_f = common_merge(Res_1[:,:,1],sm_ent)\n",
    "    Res_1[:,:,1]=soma_f\n",
    "\n",
    "    #remove possible artifacts\n",
    "    small_soma = small_soma_to_proc(Res_1[:,:,1],int(0.9*max_min[1]),dilation=False)\n",
    "    Res_1[:,:,1]-=small_soma\n",
    "\n",
    "    Res_1[:,:,0] = Res_1[:,:,0]-Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    #remove large region classified as soma Area>500\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=int(1.15*max_min[0]))\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=max_min[0])\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "    #remove processes without soma\n",
    "    Res_1_filt = art_rem(Res_1[:,:,1],Res_1[:,:,0])\n",
    "    Res_1*=Res_1_filt[:,:,np.newaxis]\n",
    "    \n",
    "    dict_im['Final_Mask_'+test_folder_str1] = Res_1\n",
    "    print(20*'%')\n",
    "    #######################################################################################################\n",
    "    #Visualization of images\n",
    "    if vis_flag:\n",
    "        vis = Visdom(port=8097, server=\"http://localhost\",env='inference_plot')\n",
    "        for key in dict_im.keys():\n",
    "            if key in ['Active Regions_'+test_folder_str1,'Enhanced_'+test_folder_str1,'Final_Mask_'+test_folder_str1]:\n",
    "                image = dict_im[key]\n",
    "                fig, ax = plt.subplots(figsize=(4,4))\n",
    "                ax.imshow(image)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(key)\n",
    "                vis.matplot(fig)\n",
    "                plt.close(fig)\n",
    "    \n",
    "    #### Extraction\n",
    "    single_astro_roi = gen_sc_mask(dict_im['Final_Mask_'+test_folder_str1])\n",
    "    dict_im = update_dict_DNN(dict_im,single_astro_roi,test_folder_str1,motion_corr,MAX_ROI_AREA_PROC,MU_PX)\n",
    "    #### save dict\n",
    "    pickle.dump(dict_im, open( \"inference_ex.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f701f4de080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Res_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_im.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dbe739dab747d38bfc63c5250e7525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(height='400px', width='1200px')), HBox(children=(VBox(children=(Dropdown(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fov_name = []\n",
    "for j in fov_list:\n",
    "    j = str(j)\n",
    "    if len(j)==1:\n",
    "        j='00'+j\n",
    "    else:\n",
    "        j='0'+j\n",
    "    fov_name.append(j)\n",
    "fov_name\n",
    "hbox,button,display_plot = layout(fov_name,dict_im)\n",
    "display(hbox)\n",
    "button.on_click(display_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual curation\n",
    "Export ROIs for ImageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROI_manual_curation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOV 002\n"
     ]
    }
   ],
   "source": [
    "#export ROIs for ImageJ\n",
    "export_roi(dict_im,fov_list,N=256,M=256,folder_save = '/media/DATA/jbonato/astro_segm/notebook/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean dictionary from ROIs and extracted traces\n",
    "dict_im = clean_dict(dict_im,fov_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI NUM 5\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 0\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 10)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 1\n",
      "ROIS 1\n",
      "SPLIT DONE (256, 256, 24)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 2\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 21)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 3\n",
      "ROIS 3\n",
      "SPLIT DONE (256, 256, 11)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 4\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 9)\n",
      "Extraction: done\n"
     ]
    }
   ],
   "source": [
    "#update dict_im with the manual curated\n",
    "for fov in fov_list:\n",
    "    folder = f'{str(fov):0>3}'\n",
    "    mask_ret = read_roi_curated(folder,N=256,M=256,folder_read='/media/DATA/jbonato/astro_segm/notebook/')\n",
    "    dict_im = update_dict_DNN(dict_im,mask_ret,folder,motion_corr,MAX_ROI_AREA_PROC,MU_PX)\n",
    "    #### save dict\n",
    "    pickle.dump(dict_im, open( \"inference_ex.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_roi2(dict_im,fov_list,N=256,M=256,folder_save = '/media/DATA/jbonato/astro_segm/notebook/'):\n",
    "    \n",
    "\n",
    "    for fov in fov_list:\n",
    "        \n",
    "        folder = f'{str(fov):0>3}'\n",
    "        #if os.path.isfile(folder_save+'ROI_'+folder+'_MC.zip'):\n",
    "        #    print('Attention: File ',folder_save+'ROI_'+folder+'_MC.zip',' already present')\n",
    "        #else:\n",
    "        print('FOV',folder)\n",
    "        list_roi = []\n",
    "\n",
    "        for key in dict_im['ROI_'+folder]:\n",
    "            buff = np.zeros((N,M))\n",
    "            a,b = dict_im['ROI_'+folder][key]\n",
    "            buff[a,b]=255\n",
    "\n",
    "            _,thresh = cv2.threshold(np.uint8(buff),127,255,0)\n",
    "            # find contours in the binary image\n",
    "            contours, _= cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "            list_roi.append(contours[0][:,0,:])\n",
    "            #list_roi.append(ImagejRoi.frompoints(contours[0][:,0,:],name=key))\n",
    "                \n",
    "    return list_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOV 002\n"
     ]
    }
   ],
   "source": [
    "el = export_roi2(dict_im,fov_list,N=256,M=256,folder_save = '/media/DATA/jbonato/astro_segm/notebook/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in el:\n",
    "    A[e[:,1],e[:,0]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f701b3d6c18>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "Res_1[:,:,:2] = Res_1[:,:,:2]+A[:,:,np.newaxis]\n",
    "plt.imshow(Res_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
