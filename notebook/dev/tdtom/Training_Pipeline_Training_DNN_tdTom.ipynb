{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage import io\n",
    "import sys\n",
    "import h5py\n",
    "import glob\n",
    "import shutil\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "import copy\n",
    " \n",
    "\n",
    "# ##################import modules\n",
    "sys.path.insert(0,'/astro_folder/RASTA/modules/')\n",
    "from aug_images import compose_tr\n",
    "\n",
    "from model.dense_up import dense_up\n",
    "from train_mod import train_model\n",
    "\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: FOV: 001\n"
     ]
    }
   ],
   "source": [
    "model_dict={'dense_up': dense_up(3)\n",
    "            }\n",
    "folder_w = '/astro_folder/weights/'\n",
    "if not(os.path.exists(folder_w)):\n",
    "    os.mkdir(folder_w)\n",
    "    print('Created',folder_w)\n",
    "    \n",
    "#########################\n",
    "model_n = 'dense_up'\n",
    "parallel_n =False\n",
    "data_dir = '/astro_folder/set4/train_single'\n",
    "workers = 1\n",
    "epochs = 15\n",
    "batch_size = 35\n",
    "lr = 1e-4\n",
    "parallel = False\n",
    "test_folders = ['1']\n",
    "#image size: this value must be divisible for 2^4 i.e. 98, 128,256,512\n",
    "N=48\n",
    "M=48\n",
    "###########################\n",
    "items = os.listdir(data_dir)\n",
    "for test_f in test_folders:\n",
    "   \n",
    "    test_folder_str = test_f\n",
    "    if len(test_folder_str)==1:\n",
    "        test_folder_str='00'+test_folder_str\n",
    "    else:\n",
    "        test_folder_str='0'+test_folder_str\n",
    "\n",
    "    print('Removing: FOV:',test_folder_str)\n",
    "    test=[]\n",
    "    query_num = len(items)\n",
    "    for i in items:\n",
    "        if 'SMALL_'+test_folder_str in i:\n",
    "            items.remove(i)\n",
    "            test.append(i)\n",
    "\n",
    "    assert query_num-len(test)==len(items),'Error in removing test folders'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im shape: (570, 1, 48, 48)\n",
      "label shape (570, 3, 48, 48)\n",
      "Training Images: 399\n",
      "Cross Validation Images: 171\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "counter2 = 0\n",
    "query_pref = 'nh'# the files in train_single folder with this suffix will not be loaded\n",
    "\n",
    "im = np.empty((N,M),dtype = np.float32)\n",
    "\n",
    "flag=True\n",
    "for item in items:\n",
    "    path_to_item = os.path.join(data_dir,item)\n",
    "    filename, file_extension = os.path.splitext(path_to_item)\n",
    "    if os.path.isfile(path_to_item) and file_extension == '.tif' and filename[-2:]!='nh':        \n",
    "        im = io.imread(path_to_item)\n",
    "        #if counter == 0: \n",
    "        if flag:\n",
    "            out_im = im\n",
    "            out_im = out_im[np.newaxis,:,:]\n",
    "        else:\n",
    "            out_im = np.concatenate((out_im,im[np.newaxis,:,:]),axis=0)\n",
    "        \n",
    "        dset= h5py.File(filename+'.hdf5','r') \n",
    "        proc_mask =  np.asarray(dset['Values'])\n",
    "        soma_mask =  np.asarray(dset['Values_soma'])\n",
    "        proc_mask[np.where(proc_mask==soma_mask)]=0\n",
    "        back = np.ones((N,M),dtype=np.int64)-proc_mask-soma_mask\n",
    "        back[back<0]=0\n",
    "        mask = np.concatenate((proc_mask[:,:,np.newaxis],soma_mask[:,:,np.newaxis],back[:,:,np.newaxis]),axis=2).astype(np.float32)\n",
    "        \n",
    "        if flag:\n",
    "            label = mask\n",
    "            label = label[np.newaxis,:,:,:]\n",
    "            flag=False\n",
    "        else:\n",
    "            label = np.concatenate((label,mask[np.newaxis,:,:,:]),axis=0)\n",
    "        \n",
    "\n",
    "label = np.swapaxes(label,1,3)\n",
    "label = np.swapaxes(label,2,3)\n",
    "\n",
    "out_im = out_im[:,np.newaxis,:,:].astype(np.float32)\n",
    "\n",
    "print('im shape:',out_im.shape)\n",
    "print('label shape', label.shape)\n",
    "\n",
    "NN = out_im.shape[0]-(out_im.shape[0]*3)//10\n",
    "#val im\n",
    "out_im_val = out_im[NN:,:,:,:]\n",
    "#tr im\n",
    "out_im =out_im[:NN,:,:,:]\n",
    "#val labels\n",
    "label_val =label[NN:,:,:,:]\n",
    "#tr labels\n",
    "label =label[:NN,:,:,:]\n",
    "\n",
    "print('Training Images:', out_im.shape[0])\n",
    "print('Cross Validation Images:', out_im_val.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 399 out of 399 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set loaded\n",
      "Training Images: 6783\n",
      "Cross Validation Images: 171\n"
     ]
    }
   ],
   "source": [
    "##blur\n",
    "param_blur = {\n",
    "    'sigma':6\n",
    "}\n",
    "N=48\n",
    "M=48\n",
    "##perspective\n",
    "Nper20 = int(N*0.2)\n",
    "Mper20 = int(M*0.2)\n",
    "pts2m = [np.float32([[0,0],[0,N],[M-Mper20,Nper20],[M-Mper20,N-Nper20]]),\n",
    "        np.float32([[Mper20,Nper20],[Mper20,N-Nper20],[M,0],[M,N]]),\n",
    "        np.float32([[0,0],[Mper20,N-Nper20],[M,0],[M-Mper20,N-Nper20]]),\n",
    "        np.float32([[Mper20,Nper20],[0,N],[M-Mper20,Nper20],[M,N]])]\n",
    "param_persp ={\n",
    "    'len':len(pts2m),\n",
    "    'pts2m': pts2m\n",
    "    }\n",
    "#optic\n",
    "param_pin = {\n",
    "     'pin_fact': -0.5 \n",
    "}\n",
    "param_bar = {\n",
    "    'bar_fact': 0.8\n",
    "}\n",
    "##elastic spec:\n",
    "param_el = {\n",
    "    'alpha': N*0.3,\n",
    "    'sigma': N*0.08,\n",
    "    'alpha_affine': N*0.08,\n",
    "    'iteration':2\n",
    "}\n",
    "########################################################################\n",
    "#Dict for augmentation\n",
    "########################################################################\n",
    "augmenters_dict = {\n",
    "    'rot':[3],\n",
    "    'blur':[1,param_blur],\n",
    "    'noise_gauss':[1],\n",
    "    'noise_sp':[1],\n",
    "    'scal1':[1],\n",
    "    'scal2':[1],\n",
    "    'persp':[param_persp['len'],param_persp],\n",
    "    'flip_ver':[1],\n",
    "    'flip_or':[1],\n",
    "    'scal_int1':[1],\n",
    "    'scal_int2':[1],\n",
    "    #'optic_pin':[1,param_pin],\n",
    "    #'optic_bar':[1,param_bar],\n",
    "    #'elastic':[param_el['iteration'],param_el]\n",
    "    }\n",
    "\n",
    "foo_list = compose_tr(augmenters_dict)\n",
    "\n",
    "\n",
    "\n",
    "n_transf=0\n",
    "for key in augmenters_dict.keys():\n",
    "    n_transf += augmenters_dict[key][0]\n",
    "print(n_transf)\n",
    "def fun (i,N,M,n_tr,foolist):\n",
    "    \n",
    "    foolambda = lambda a,b,foolist : [x(a,b) for x in foolist]\n",
    "    sample = np.empty((n_tr,4,N,M))\n",
    "    \n",
    "    k = foolambda(out_im[i,0,:,:],np.dstack((label[i,0,:,:],label[i,1,:,:])),foolist)\n",
    "    c_ind = 0\n",
    "    for j in range(len(k)):\n",
    "        disc = k[j][0].shape\n",
    "        if len(disc)==3:\n",
    "            ind = disc[0]\n",
    "        else:\n",
    "            ind=1\n",
    "        sample[c_ind:c_ind+ind,0,:,:]=k[j][0]\n",
    "        sample[c_ind:c_ind+ind,1:,:,:]=k[j][1]\n",
    "        c_ind+=ind\n",
    "\n",
    "    del k\n",
    "    return sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_samples = Parallel(n_jobs=12,verbose=1,require='sharedmem')(delayed(fun) (i,N,M,n_transf,foo_list) for i in range(out_im.shape[0]))\n",
    "list_samples = np.asarray(list_samples)\n",
    "rank,batch,ch,N,M = list_samples.shape\n",
    "list_samples = list_samples.reshape(rank*batch,ch,N,M)\n",
    "\n",
    "out_im = np.vstack((out_im,list_samples[:,0,:,:][:,np.newaxis,:,:]))\n",
    "label = np.vstack((label,list_samples[:,1:,:,:]))\n",
    "label[label<0.2]=0.0\n",
    "label[label>=0.2]=1.0\n",
    "\n",
    "print('Training set loaded\\nTraining Images:', out_im.shape[0])\n",
    "print('Cross Validation Images:', out_im_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 6783, 'val': 171}\n"
     ]
    }
   ],
   "source": [
    "mean_out_im =  np.mean(np.mean(out_im,axis=3),axis=2)\n",
    "mean_out_im_val = np.mean(np.mean(out_im_val,axis=3),axis=2)\n",
    "\n",
    "out_im = (out_im-mean_out_im[:,:,np.newaxis,np.newaxis])\n",
    "out_im_val = (out_im_val-mean_out_im_val[:,:,np.newaxis,np.newaxis])\n",
    "\n",
    "class SimDataset(Dataset):\n",
    "    def __init__(self,flag=True):\n",
    "        if flag:\n",
    "            self.input_images, self.target_masks = out_im[:,:,:,:],label[:,:,:,:]     \n",
    "        else:\n",
    "            self.input_images, self.target_masks = out_im_val[:,:,:,:],label_val[:,:,:,:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "    \n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        image = torch.from_numpy(image).float()\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        return [image, mask]\n",
    "\n",
    "\n",
    "train_set = SimDataset()\n",
    "val_set = SimDataset(flag = False)\n",
    "\n",
    "image_datasets = {\n",
    "    'train': train_set, 'val': val_set\n",
    "}\n",
    "\n",
    "if parallel:\n",
    "    batch_size =3*batch_size\n",
    "else:\n",
    "    batch_size =batch_size\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1),\n",
    "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "}\n",
    "\n",
    "\n",
    "dataset_sizes = {\n",
    "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
    "}\n",
    "\n",
    "print(dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training stuff\n",
    "\n",
    "- Freezing layers\n",
    "- Parallel Training\n",
    "- Single Loss flag\n",
    "- Set weights filename\n",
    "- Training parameters scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- \n",
      " MODEL dense_up\n"
     ]
    }
   ],
   "source": [
    "# model to import\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model_dict[model_n]\n",
    "print(10*'-','\\n','MODEL',str(model_n))\n",
    "ct=0\n",
    "if model == 'dense_up':\n",
    "    #for child in model.children():\n",
    "    for child in model.children():\n",
    "        if ct>1 and ct<5:\n",
    "            print('freezing child', ct)\n",
    "            for params in child.parameters():\n",
    "                params.requires_grad=False\n",
    "        ct += 1\n",
    "\n",
    "if parallel_n:\n",
    "    model = nn.DataParallel(model,device_ids=[0,1,2])\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if model_n == 'dense_up' or model_n == 'UNet' :\n",
    "    single_loss =True\n",
    "else:\n",
    "    single_loss = False\n",
    "\n",
    "weights_str=folder_w+model_n+test_folder_str+'_set1.pt'\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.MultiStepLR(optimizer_ft, milestones=[6,30], gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visdom for live training and cross validation loss \n",
    "\n",
    "You can use visdom typyng visdom in your bash or creating a tmux session. Than navigate to \n",
    "\n",
    "http://localhost:8097\n",
    "\n",
    "If you are running the notebook on a server you must establish a ssh connection \n",
    "\n",
    "ssh -N -L 8097:localhost:8097 user@server_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_visdom = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the net with Inception-ResNet-v2 blocks freezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.334358, dice: 1.255216, loss: 1.422395\n",
      "val: bce: 0.226238, dice: 0.970488, loss: 1.083607\n",
      "saving best model\n",
      "1m 19s\n",
      "Epoch 1/11\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.193316, dice: 0.987588, loss: 1.084246\n",
      "val: bce: 0.171701, dice: 0.772265, loss: 0.858116\n",
      "saving best model\n",
      "1m 20s\n",
      "Epoch 2/11\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.161949, dice: 0.864057, loss: 0.945031\n",
      "val: bce: 0.157856, dice: 0.739031, loss: 0.817959\n",
      "saving best model\n",
      "1m 20s\n",
      "Epoch 3/11\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.146342, dice: 0.782740, loss: 0.855911\n",
      "val: bce: 0.160216, dice: 0.676553, loss: 0.756660\n",
      "saving best model\n",
      "1m 20s\n",
      "Epoch 4/11\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.139096, dice: 0.732621, loss: 0.802169\n",
      "val: bce: 0.169533, dice: 0.672072, loss: 0.756838\n",
      "1m 20s\n",
      "Epoch 5/11\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.125718, dice: 0.673883, loss: 0.736742\n",
      "val: bce: 0.180725, dice: 0.662630, loss: 0.752992\n",
      "saving best model\n",
      "1m 20s\n",
      "Epoch 6/11\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.109142, dice: 0.595118, loss: 0.649689\n",
      "val: bce: 0.169031, dice: 0.628047, loss: 0.712562\n",
      "saving best model\n",
      "1m 20s\n",
      "Epoch 7/11\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.103038, dice: 0.568706, loss: 0.620226\n",
      "val: bce: 0.173782, dice: 0.626666, loss: 0.713558\n",
      "1m 21s\n",
      "Epoch 8/11\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.099898, dice: 0.549962, loss: 0.599911\n",
      "val: bce: 0.173043, dice: 0.618654, loss: 0.705175\n",
      "saving best model\n",
      "1m 21s\n",
      "Epoch 9/11\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.097410, dice: 0.532619, loss: 0.581324\n",
      "val: bce: 0.175006, dice: 0.618721, loss: 0.706224\n",
      "1m 20s\n",
      "Epoch 10/11\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.096183, dice: 0.523809, loss: 0.571901\n",
      "val: bce: 0.175580, dice: 0.626137, loss: 0.713927\n",
      "1m 21s\n",
      "Epoch 11/11\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.092985, dice: 0.508370, loss: 0.554862\n",
      "val: bce: 0.179698, dice: 0.621156, loss: 0.711005\n",
      "1m 21s\n",
      "Best val loss: 0.705175\n"
     ]
    }
   ],
   "source": [
    "model,loss_val,_,_ = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=epochs-3,\\\n",
    "                                 dataloaders=dataloaders,device=device,single_loss=single_loss,\\\n",
    "                                 use_visdom=use_visdom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freezing child 2\n",
      "freezing child 3\n",
      "freezing child 4\n",
      "Epoch 0/2\n",
      "----------\n",
      "LR 5e-06\n",
      "train: bce: 0.096964, dice: 0.532980, loss: 0.581462\n",
      "val: bce: 0.176776, dice: 0.619234, loss: 0.707622\n",
      "1m 22s\n",
      "Epoch 1/2\n",
      "----------\n",
      "LR 5e-06\n",
      "train: bce: 0.098204, dice: 0.534300, loss: 0.583403\n",
      "val: bce: 0.164883, dice: 0.655015, loss: 0.737456\n",
      "1m 22s\n",
      "Epoch 2/2\n",
      "----------\n",
      "LR 5e-06\n",
      "train: bce: 0.098523, dice: 0.551932, loss: 0.601193\n",
      "val: bce: 0.170821, dice: 0.632911, loss: 0.718322\n",
      "1m 22s\n",
      "Best val loss: 0.705175\n"
     ]
    }
   ],
   "source": [
    "if model_n == 'dense_up':\n",
    "    ct=0\n",
    "    for child in model.children():\n",
    "    #for child in model.module.children():\n",
    "        if ct>1 and ct<5:\n",
    "            print('freezing child', ct)\n",
    "            for params in child.parameters():\n",
    "                params.requires_grad=True\n",
    "        ct += 1\n",
    "\n",
    "    optimizer_ft = optim.Adam(model.parameters(), lr=(0.05*lr))\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=200, gamma=0.1)\n",
    "    \n",
    "    model,loss_val,_,_ = train_model(model, optimizer_ft, exp_lr_scheduler,num_epochs=3,\\\n",
    "                                     best_loss=loss_val,dataloaders=dataloaders,device=device,\\\n",
    "                                     single_loss=single_loss,use_visdom=use_visdom)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qq =  model.module.state_dict()\n",
    "qq = model.state_dict()\n",
    "for k, v in qq.items():\n",
    "    qq[k] = v.cpu()\n",
    "torch.save(qq,weights_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###free mem\n",
    "del model,out_im,out_im_val,label,label_val,train_set,val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
